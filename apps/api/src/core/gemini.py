import os
from typing import List

from anyio import to_thread

from src.core.config import settings
from src.services.prompt_registry import RECRUITER_PERSONA as PR_PERSONA, build_role_guidance_block as PR_ROLE_BLOCK


# --- Dynamic import for new client API ---
try:
    from google import genai  # type: ignore

    _GENAI_AVAILABLE = True
except ImportError:
    _GENAI_AVAILABLE = False


GEMINI_API_KEY = settings.gemini_api_key
MODEL_NAME = "gemini-2.5-flash"

# Advanced LLM-driven recruiter persona with intelligent question diversity
RECRUITER_PERSONA = (
    "Sen deneyimli TÃ¼rk Ä°K uzmanÄ± 'Ece'sin. Profesyonel, objektif ve analitik yaklaÅŸÄ±mla mÃ¼lakat yaparsÄ±n. "
    "AmacÄ±n: AdaylarÄ± iÅŸ gereksinimlerine gÃ¶re adil ama kritik bir ÅŸekilde DEÄERLENDÄ°RMEK. "
    "KiÅŸiliÄŸin: DoÄŸrudan, profesyonel ve tarafsÄ±z - aÅŸÄ±rÄ± pozitif veya negatif deÄŸil. "
    
    "ğŸ¯ SORU Ã‡EÅÄ°TLÄ°LÄ°ÄÄ° VE AKILLI KONUÅMA YÃ–NETÄ°MÄ°:"
    "- Her soru FARKLI bir yetkinlik alanÄ±nÄ± keÅŸfetmeli (teknik, davranÄ±ÅŸsal, liderlik, problem Ã§Ã¶zme, takÄ±m Ã§alÄ±ÅŸmasÄ±, iletiÅŸim vb.)"
    "- Ã–nceki sorulardan TAMAMEN farklÄ± konular seÃ§ - aynÄ± temalarÄ± tekrarlama"
    "- Soru tiplerini akÄ±llÄ±ca deÄŸiÅŸtir: somut Ã¶rnek â†’ durum analizi â†’ varsayÄ±msal senaryo â†’ derinlemesine sondaj"
    "- KonuÅŸma akÄ±ÅŸÄ±nÄ± doÄŸal tut: 'anladÄ±m', 'peki', 'tamam' gibi kÄ±sa geÃ§iÅŸler kullan ama doÄŸal olsun"
    
    "ğŸ” SOMUT Ã–RNEK Ã‡IKARMA TEKNÄ°KLERÄ°:"
    "- Belirsiz cevaplara karÅŸÄ± derhal sonda: 'NasÄ±l Ã¶lÃ§tÃ¼nÃ¼z bu sonucu?', 'Hangi zorluklar yaÅŸadÄ±nÄ±z?', 'Kim dahil oldu bu sÃ¼rece?'"
    "- STAR metodunu doÄŸal ÅŸekilde Ã§Ä±kar ama hiÃ§ sÃ¶yleme - sadece sorularÄ±n sonuÃ§ta STAR Ã§Ä±kartacak ÅŸekilde tasarla"
    "- Her cevap iÃ§in en az 2-3 follow-up soru hazÄ±rla zihninde"
    
    "âŒ YASAKLAR:"
    "- 'GÃ¼zel', 'harika', 'mÃ¼kemmel', 'Ã§ok iyi' gibi aÅŸÄ±rÄ± Ã¶vgÃ¼ YASAK"
    "- AynÄ± konuyu tekrar sormak YASAK (Ã¶rn: iki kez takÄ±m Ã§alÄ±ÅŸmasÄ± sormak)"
    "- Genel sorular sormak YASAK (Ã¶rn: 'Bir Ã¶rnek verir misiniz?')"
    "- CV'de olmayan deneyimler hakkÄ±nda sormak YASAK"
    
    "âš¡ Ä°LETÄ°ÅÄ°M TARZI:"
    "- Cinsiyet-tarafsÄ±z hitap et, hiÃ§bir varsayÄ±mda bulunma"
    "- Profesyonel Ä°K dili kullan: 'somut Ã¶rnek verebilir misiniz', 'nasÄ±l yaklaÅŸtÄ±nÄ±z', 'hangi yÃ¶ntemleri kullandÄ±nÄ±z'"
    "- DinlediÄŸini gÃ¶ster: kÄ±sa onaylamalarla geÃ§iÅŸ yap"
    "- Eksik deneyim varsa transferable skills keÅŸfet ama profili yapay olarak yÃ¼kseltme"
)


def _sync_generate(history: List[dict[str, str]], job_context: str | None = None, max_questions: int = 50):
    """Blocking Gemini request executed in a thread."""

    if not _GENAI_AVAILABLE:
        raise RuntimeError("google-ai-python library not installed (pip install google-ai-python)")

    from google import genai as _genai  # type: ignore
    client = _genai.Client(api_key=GEMINI_API_KEY)

    system_prompt = (
        PR_PERSONA +
        "\n\nğŸ¯ AKILLI MÃœLAKAT STRATEJISI - LLM ODAKLI YAKLAÅIM:"
        "Sen bu mÃ¼lakatÄ± OBJEKTIF DEÄERLENDÄ°RME amacÄ±yla yÃ¼rÃ¼tÃ¼yorsun. YaklaÅŸÄ±mÄ±n analitik olmalÄ±, cesaretlendirici deÄŸil. GÃ¼Ã§lÃ¼ yanlarÄ± VE eksikleri tespit etmeye odaklan. "
        
        "\nğŸ“‹ KONUÅMA AKIÅI VE Ã‡EÅÄ°TLÄ°LÄ°K KONTROLÃœ:"
        "- GeÃ§miÅŸ konuÅŸmayÄ± analiz et: Hangi yetkinlik alanlarÄ± keÅŸfedildi? Hangileri eksik?"
        "- Her yeni soru FARKLI bir alanÄ± kapsamalÄ±: teknik beceriler â†’ problem Ã§Ã¶zme â†’ takÄ±m dinamikleri â†’ liderlik â†’ iletiÅŸim â†’ stres yÃ¶netimi vb."
        "- Soru formatlarÄ±nÄ± zekice deÄŸiÅŸtir: deneyim sorusu â†’ varsayÄ±msal durum â†’ somut Ã¶rnek isteme â†’ derinlemesine sondaj"
        "- AynÄ± temalarÄ± tekrarlama - Ã¶rneÄŸin zaten takÄ±m Ã§alÄ±ÅŸmasÄ± sorduÄŸun konuyu tekrar aÃ§ma"
        
        "\nğŸ” CV-Ä°Å UYUM ANALÄ°ZÄ° (KRÄ°TÄ°K):"
        "- Deneyim sorularÄ± sormadan Ã–NCE, CV'de o alanda deneyim var mÄ± kontrol et"
        "- CV'de olmayan sektÃ¶rler/domainler hakkÄ±nda 'hangi projede zorlandÄ±nÄ±z' gibi sorular YASAK"
        "- SektÃ¶r uyumsuzluÄŸu varsa aÃ§Ä±k sor: 'Bu pozisyon [sektÃ¶r] deneyimi gerektiriyor, bu alanda deneyiminiz var mÄ±?'"
        "- CV'deki gerÃ§ek deneyimi iÅŸ gereksinimlerini karÅŸÄ±laÅŸtÄ±r, eksiklikler varsa doÄŸrudan sonda"
        
        "\nğŸ’¡ SORU Ã–RNEKLERÄ° VE TEKNÄ°KLER:"
        "- Durum yaratma: 'Diyelim ki [iÅŸ senaryosu], bu durumda nasÄ±l hareket edersiniz?'"
        "- ZorluklarÄ± keÅŸfet: 'X alanÄ±ndaki deneyiminizden en zorlandÄ±ÄŸÄ±nÄ±z durum neydi?' (sadece CV'de olan alanlarda!)"
        "- Belirsiz cevaplarÄ± sonda: EÄŸer 'takÄ±m Ã§alÄ±ÅŸmasÄ± yaptÄ±m' derse â†’ 'NasÄ±l Ã§atÄ±ÅŸmalarÄ± Ã§Ã¶zdÃ¼nÃ¼z?', 'Hangi roller Ã¼stlendiniz?'"
        "- Somut kanÄ±t iste: 'SonuÃ§larÄ± nasÄ±l Ã¶lÃ§tÃ¼nÃ¼z?', 'Hangi metrikleri kullandÄ±nÄ±z?', 'Timeline nasÄ±ldÄ±?'"
        
        "\nâ° MÃœLAKAT ZAMANLAMA:"
        "- En az 5-6 derinlemesine yetkinlik sorusu sor (farklÄ± alanlarda)"
        "- Sonra maaÅŸ beklentisini sor: 'MaaÅŸ beklentiniz nedir?'"
        "- MaaÅŸ sorusunu Ã§ok erken sorma (5 sorudan Ã¶nce)"
        "- TÃ¼m temel yetkinlikleri deÄŸerlendirdikten VE maaÅŸ sorusunu sorduktan sonra 'FINISHED' yaz"
        
        "\nğŸš« KESIN YASAKLAR:"
        "- CV'de aÃ§Ä±kÃ§a yazÄ±lmayan ÅŸeylerden bahsetme: 'Ã–zgeÃ§miÅŸinizde X gÃ¶rÃ¼yorum' deme (eÄŸer X gerÃ§ekten yazÄ±lÄ± deÄŸilse)"
        "- AÅŸÄ±rÄ± Ã¶vgÃ¼ YASAK: 'gÃ¼zel', 'harika', 'mÃ¼kemmel' kelimelerini kullanma"
        "- Konu dÄ±ÅŸÄ±na Ã§Ä±kma - rol, iÅŸ tanÄ±mÄ±, yetkinliklere odaklan"
        "- Cinsiyet varsayÄ±mlarÄ± yapma - herkese tarafsÄ±z hitap et"
        
        "\nğŸª AKILLI KONUÅMA YÃ–NETÄ°MÄ°:"
        "- KÄ±sa doÄŸal geÃ§iÅŸler kullan: 'anladÄ±m', 'peki', 'tamam' - ama abartma"
        "- DinlediÄŸini gÃ¶ster ama sonra yeni konuya geÃ§"
        "- Transferable skills keÅŸfet ama profili yapay olarak yÃ¼kseltme"
        "- Profesyonel Ä°K dili kullan: 'somut Ã¶rnek', 'nasÄ±l yaklaÅŸtÄ±nÄ±z', 'hangi yÃ¶ntemleri kullandÄ±nÄ±z'"
    )
    if job_context:
        # Accept larger context to include full resume and extras (no truncation here; upstream controls size)
        system_prompt += (
            "\n\nContext (job description, full resume, and extra questions):\n" + job_context
        )
        # Inject role guidance if we can detect the role from job description
        try:
            system_prompt += "\n\n" + PR_ROLE_BLOCK(job_context)
        except Exception:
            pass

    convo_text = system_prompt + "\n\n"
    for turn in history:
        prefix = "Candidate:" if turn["role"] == "user" else "Interviewer:"
        convo_text += f"{prefix} {turn['text']}\n"
    convo_text += "Interviewer:"

    response = client.models.generate_content(
        model=MODEL_NAME,
        contents=convo_text,
        # Note: current google-genai client does not support generation_config param
    )

    text = (response.text or "").strip()
    if text.upper().strip() == "FINISHED":
        return {"question": "", "done": True}
    return {"question": text, "done": False}


def _fallback_generate(history: List[dict[str, str]], job_context: str | None = None, max_questions: int = 50) -> dict[str, str | bool]:
    """Deterministic local fallback when Gemini is not configured.

    Prioritizes job-specific scenarios, then falls back to generic questions.
    """
    # Try to extract job description for dynamic scenarios
    job_desc = ""
    if job_context:
        # Look for job description in context
        lines = job_context.split('\n')
        for line in lines:
            if 'Ä°ÅŸ TanÄ±mÄ±:' in line or 'Job Description:' in line:
                job_desc = line.split(':', 1)[1].strip() if ':' in line else ""
                break
        if not job_desc and job_context:
            # Use first part of context as job description
            job_desc = job_context.split('\n')[0][:1000]
    
    # Prefer resume-keyword targeted canned questions if available in job_context  
    def _extract_keywords_from_ctx(ctx: str) -> list[str]:
        import re as _re
        # Expect a line like: Internal Resume Keywords: kw1, kw2, kw3
        m = _re.search(r"Internal Resume Keywords:\s*(.+)", ctx or "", flags=_re.IGNORECASE)
        if not m:
            return []
        part = m.group(1)
        kws = [t.strip() for t in part.split(",") if t.strip()]
        return kws[:6]

    targeted: list[str] = []
    kws = _extract_keywords_from_ctx(job_context or "") if job_context else []
    for k in kws:
        targeted.append(f"Ã–zgeÃ§miÅŸinizde '{k}' geÃ§miÅŸ. Bu konuda hangi problemi nasÄ±l Ã§Ã¶zdÃ¼nÃ¼z ve Ã¶lÃ§Ã¼lebilir sonuÃ§ neydi?")
    
    # Job-specific scenarios (this would be populated from dynamic generation in real usage)
    job_specific_scenarios: list[str] = []
    
    # Fallback generic situational scenarios
    generic_situational_questions = [
        "Diyelim ki ekibinizde Ã§atÄ±ÅŸma yaÅŸayan iki meslektaÅŸÄ±nÄ±z var ve bu durum projeyi etkiliyor. Bu durumda nasÄ±l mÃ¼dahale edersiniz?",
        "SÄ±kÄ± bir deadline'Ä±nÄ±z var ama projenin kalitesinden Ã¶dÃ¼n vermek istemiyorsunuz. Ã–ncelikleri nasÄ±l belirlersiniz?",
        "Yeni bir teknoloji Ã¶ÄŸrenmeniz gereken acil bir proje verildi. NasÄ±l yaklaÅŸÄ±rsÄ±nÄ±z?",
        "Bir projede beklediÄŸiniz sonuÃ§larÄ± alamadÄ±ÄŸÄ±nÄ±z bir dÃ¶nem yaÅŸadÄ±nÄ±z mÄ±? Bu durumu nasÄ±l Ã§Ã¶zdÃ¼nÃ¼z?",
        "Ä°ÅŸ arkadaÅŸlarÄ±nÄ±zdan birinin sÃ¼rekli geÃ§ kaldÄ±ÄŸÄ± ve ekip performansÄ±nÄ± etkilediÄŸi bir durumla karÅŸÄ±laÅŸtÄ±nÄ±z mÄ±? NasÄ±l ele aldÄ±nÄ±z?",
        "Daha Ã¶nce hiÃ§ yapmadÄ±ÄŸÄ±nÄ±z bir iÅŸi teslim etmeniz gerektiÄŸi bir durumda neler yaptÄ±nÄ±z?",
        "MÃ¼ÅŸteri/kullanÄ±cÄ± ÅŸikayetleri aldÄ±ÄŸÄ±nÄ±z bir projede nasÄ±l hareket ettiniz?",
        "KaynaklarÄ±n kÄ±sÄ±tlÄ± olduÄŸu bir projede nasÄ±l Ã§Ã¶zÃ¼m Ã¼rettiniz?",
    ]
    
    # Mix targeted, job-specific, and generic questions in priority order
    canned = targeted + job_specific_scenarios + generic_situational_questions + [
        "Ã–zgeÃ§miÅŸinizde Ã¶ne Ã§Ä±kan bir proje/baÅŸarÄ±yÄ± STAR Ã§erÃ§evesinde kÄ±saca anlatÄ±r mÄ±sÄ±nÄ±z?",
        "Son rolÃ¼nÃ¼zde somut bir katkÄ±nÄ±zÄ± ve sonucunu paylaÅŸÄ±r mÄ±sÄ±nÄ±z?",
    ]
    asked = sum(1 for t in history if t.get("role") == "assistant")
    # Respect hard question limit first
    if asked < len(canned):
        return {"question": canned[asked], "done": False}
    # Keep going without finishing: vary phrasing slightly
    return {"question": "Ã–zgeÃ§miÅŸinizden baÅŸka bir proje veya baÅŸarÄ±yÄ± kÄ±saca STAR Ã§erÃ§evesinde paylaÅŸÄ±r mÄ±sÄ±nÄ±z?", "done": False}


async def generate_question(history: List[dict[str, str]], job_context: str | None = None, max_questions: int = 7) -> dict[str, str | bool]:
    # If API key or library missing, use fallback for smooth local dev
    if not GEMINI_API_KEY or not _GENAI_AVAILABLE:
        return _fallback_generate(history, job_context, max_questions)

    try:
        return await to_thread.run_sync(_sync_generate, history, job_context, max_questions)
    except Exception:
        # Last-resort fallback
        return _fallback_generate(history, job_context, max_questions)


async def polish_question(text: str) -> str:
    """Optionally send the generated question to the LLM to smooth tone.

    Kept optional with strict fallback to original text.
    """
    if not GEMINI_API_KEY or not _GENAI_AVAILABLE:
        return text
    try:
        def _sync(t: str):
            from google import genai as _genai  # type: ignore
            client = _genai.Client(api_key=GEMINI_API_KEY)
            prompt = (
                "AÅŸaÄŸÄ±daki soruyu TÃ¼rkÃ§e, kÄ±sa ve doÄŸal bir Ã¼slupla nazikÃ§e yeniden yaz.\n"
                "Tek cÃ¼mle ve soru iÅŸaretiyle bitir. Yapay ve mekanik duygudan kaÃ§Ä±n, hafif insansÄ± ton kat:\n\n" + t
            )
            resp = client.models.generate_content(model=MODEL_NAME, contents=prompt)
            cleaned = (resp.text or t).strip()
            return cleaned or t
        return await to_thread.run_sync(_sync, text)
    except Exception:
        return text


# --- OpenAI fallback (HTTP) ---

def _openai_sync_generate(history: List[dict[str, str]], job_context: str | None = None, max_questions: int = 50) -> dict[str, str | bool]:
    """Blocking OpenAI request executed in a thread (chat.completions)."""
    api_key = settings.openai_api_key
    if not api_key:
        raise RuntimeError("OPENAI_API_KEY not configured")
    import httpx  # local import to avoid import when unused

    system_prompt = (
        RECRUITER_PERSONA +
        "\n\nğŸ¯ AKILLI MÃœLAKAT STRATEJISI - LLM ODAKLI YAKLAÅIM:"
        "Sen bu mÃ¼lakatÄ± OBJEKTIF DEÄERLENDÄ°RME amacÄ±yla yÃ¼rÃ¼tÃ¼yorsun. YaklaÅŸÄ±mÄ±n analitik olmalÄ±, cesaretlendirici deÄŸil. GÃ¼Ã§lÃ¼ yanlarÄ± VE eksikleri tespit etmeye odaklan. "
        
        "\nğŸ“‹ KONUÅMA AKIÅI VE Ã‡EÅÄ°TLÄ°LÄ°K KONTROLÃœ:"
        "- GeÃ§miÅŸ konuÅŸmayÄ± analiz et: Hangi yetkinlik alanlarÄ± keÅŸfedildi? Hangileri eksik?"
        "- Her yeni soru FARKLI bir alanÄ± kapsamalÄ±: teknik beceriler â†’ problem Ã§Ã¶zme â†’ takÄ±m dinamikleri â†’ liderlik â†’ iletiÅŸim â†’ stres yÃ¶netimi vb."
        "- Soru formatlarÄ±nÄ± zekice deÄŸiÅŸtir: deneyim sorusu â†’ varsayÄ±msal durum â†’ somut Ã¶rnek isteme â†’ derinlemesine sondaj"
        "- AynÄ± temalarÄ± tekrarlama - Ã¶rneÄŸin zaten takÄ±m Ã§alÄ±ÅŸmasÄ± sorduÄŸun konuyu tekrar aÃ§ma"
        
        "\nğŸ” CV-Ä°Å UYUM ANALÄ°ZÄ° (KRÄ°TÄ°K):"
        "- Deneyim sorularÄ± sormadan Ã–NCE, CV'de o alanda deneyim var mÄ± kontrol et"
        "- CV'de olmayan sektÃ¶rler/domainler hakkÄ±nda 'hangi projede zorlandÄ±nÄ±z' gibi sorular YASAK"
        "- SektÃ¶r uyumsuzluÄŸu varsa aÃ§Ä±k sor: 'Bu pozisyon [sektÃ¶r] deneyimi gerektiriyor, bu alanda deneyiminiz var mÄ±?'"
        "- CV'deki gerÃ§ek deneyimi iÅŸ gereksinimlerini karÅŸÄ±laÅŸtÄ±r, eksiklikler varsa doÄŸrudan sonda"
        
        "\nğŸ’¡ SORU Ã–RNEKLERÄ° VE TEKNÄ°KLER:"
        "- Durum yaratma: 'Diyelim ki [iÅŸ senaryosu], bu durumda nasÄ±l hareket edersiniz?'"
        "- ZorluklarÄ± keÅŸfet: 'X alanÄ±ndaki deneyiminizden en zorlandÄ±ÄŸÄ±nÄ±z durum neydi?' (sadece CV'de olan alanlarda!)"
        "- Belirsiz cevaplarÄ± sonda: EÄŸer 'takÄ±m Ã§alÄ±ÅŸmasÄ± yaptÄ±m' derse â†’ 'NasÄ±l Ã§atÄ±ÅŸmalarÄ± Ã§Ã¶zdÃ¼nÃ¼z?', 'Hangi roller Ã¼stlendiniz?'"
        "- Somut kanÄ±t iste: 'SonuÃ§larÄ± nasÄ±l Ã¶lÃ§tÃ¼nÃ¼z?', 'Hangi metrikleri kullandÄ±nÄ±z?', 'Timeline nasÄ±ldÄ±?'"
        
        "\nâ° MÃœLAKAT ZAMANLAMA:"
        "- En az 5-6 derinlemesine yetkinlik sorusu sor (farklÄ± alanlarda)"
        "- Sonra maaÅŸ beklentisini sor: 'MaaÅŸ beklentiniz nedir?'"
        "- MaaÅŸ sorusunu Ã§ok erken sorma (5 sorudan Ã¶nce)"
        "- TÃ¼m temel yetkinlikleri deÄŸerlendirdikten VE maaÅŸ sorusunu sorduktan sonra 'FINISHED' yaz"
        
        "\nğŸš« KESIN YASAKLAR:"
        "- CV'de aÃ§Ä±kÃ§a yazÄ±lmayan ÅŸeylerden bahsetme: 'Ã–zgeÃ§miÅŸinizde X gÃ¶rÃ¼yorum' deme (eÄŸer X gerÃ§ekten yazÄ±lÄ± deÄŸilse)"
        "- AÅŸÄ±rÄ± Ã¶vgÃ¼ YASAK: 'gÃ¼zel', 'harika', 'mÃ¼kemmel' kelimelerini kullanma"
        "- Konu dÄ±ÅŸÄ±na Ã§Ä±kma - rol, iÅŸ tanÄ±mÄ±, yetkinliklere odaklan"
        "- Cinsiyet varsayÄ±mlarÄ± yapma - herkese tarafsÄ±z hitap et"
        
        "\nğŸª AKILLI KONUÅMA YÃ–NETÄ°MÄ°:"
        "- KÄ±sa doÄŸal geÃ§iÅŸler kullan: 'anladÄ±m', 'peki', 'tamam' - ama abartma"
        "- DinlediÄŸini gÃ¶ster ama sonra yeni konuya geÃ§"
        "- Transferable skills keÅŸfet ama profili yapay olarak yÃ¼kseltme"
        "- Profesyonel Ä°K dili kullan: 'somut Ã¶rnek', 'nasÄ±l yaklaÅŸtÄ±nÄ±z', 'hangi yÃ¶ntemleri kullandÄ±nÄ±z'"
    )
    if job_context:
        system_prompt += ("\n\nContext (job description and full resume text may be included):\n" + job_context[:8000])

    messages = [{"role": "system", "content": system_prompt}]
    for turn in history:
        role = "user" if turn["role"] == "user" else "assistant"
        messages.append({"role": role, "content": turn["text"]})

    payload = {
        "model": "gpt-4o-mini",
        "messages": messages,
        "temperature": 0.3,
        # Allow longer, fully-formed questions (prevents truncation)
        "max_tokens": 220,
    }
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    with httpx.Client(timeout=5.0) as client:
        resp = client.post("https://api.openai.com/v1/chat/completions", json=payload, headers=headers)
        resp.raise_for_status()
        data = resp.json()
    text = (data.get("choices", [{}])[0].get("message", {}).get("content", "").strip())
    if text.upper().strip() == "FINISHED":
        return {"question": "", "done": True}
    return {"question": text, "done": False}


async def generate_question_robust(history: List[dict[str, str]], job_context: str | None = None, max_questions: int = 7, total_timeout_s: float = 5.0) -> dict[str, str | bool]:
    """Two-tier LLM strategy: OpenAI first, then Gemini; last resort local canned.

    OpenAI (gpt-4o-mini) is preferred for lower latency and Turkish fluency; Gemini remains as backup.
    """
    # 1) OpenAI (preferred)
    try:
        return await to_thread.run_sync(_openai_sync_generate, history, job_context, max_questions)
    except Exception:
        pass

    # 2) Gemini (backup)
    try:
        return await to_thread.run_sync(_sync_generate, history, job_context, max_questions)
    except Exception:
        pass

    # 3) Local canned
    return _fallback_generate(history, job_context, max_questions)


def _fallback_requirements(text: str) -> dict:
    # Deprecated: manual requirements/rubric extraction removed
    return {}


async def extract_requirements_from_text(text: str) -> dict:
    """Deprecated helper kept for compatibility; returns empty config."""
    return {}


async def generate_job_specific_scenarios(job_desc: str) -> list[str]:
    """Generate situational interview questions based on job description requirements."""
    from src.core.config import settings
    if not (settings.openai_api_key and job_desc.strip()):
        return []
    
    import httpx
    
    prompt = f"""Ä°ÅŸ tanÄ±mÄ±nÄ± analiz et ve bu pozisyonda GERÃ‡EKTEN yaÅŸanabilecek spesifik durumlarÄ± konu alan sorular oluÅŸtur.

Ä°ÅŸ TanÄ±mÄ±: {job_desc[:3000]}

GÃ–REV: Bu iÅŸte Ã§alÄ±ÅŸan birinin karÅŸÄ±laÅŸabileceÄŸi 5-6 gerÃ§ekÃ§i durum sorusu yaz.

ZORUNLU KURALLAR:
1. Her soru o iÅŸin GÃœNLÃœK GERÃ‡EKLÄ°ÄÄ°NDEN alÄ±nmalÄ± (mÃ¼ÅŸteri, takÄ±m, sÃ¼reÃ§, problem Ã§Ã¶zme)
2. Soru formatÄ±: "Bu iÅŸte [spesifik durum]. NasÄ±l yaklaÅŸÄ±rsÄ±nÄ±z?" 
3. Her soru farklÄ± yetkinliÄŸi test etmeli (mÃ¼ÅŸteri iliÅŸkisi, problem Ã§Ã¶zme, stres yÃ¶netimi, takÄ±m Ã§alÄ±ÅŸmasÄ±, Ã¶ncelik belirleme)
4. YASAKLI: E-posta, araÃ§ sorular, Ã¶zgeÃ§miÅŸ sorularÄ±, genel yaklaÅŸÄ±m sorularÄ±

Ã–RNEK KALITE (SatÄ±ÅŸ DanÄ±ÅŸmanÄ± iÃ§in):
âœ“ "MÃ¼ÅŸteri beÄŸendiÄŸi Ã¼rÃ¼nÃ¼n fiyatÄ±nÄ± Ã§ok yÃ¼ksek bulduÄŸunu sÃ¶ylÃ¼yor ve gitmek istiyor. NasÄ±l yaklaÅŸÄ±rsÄ±nÄ±z?"
âœ— "Hangi iletiÅŸim yÃ¶ntemlerini kullanÄ±rsÄ±nÄ±z?" (Ã§ok genel)

Sadece soru listesi dÃ¶n, baÅŸka yazma."""
    
    headers = {"Authorization": f"Bearer {settings.openai_api_key}"}
    body = {"model": "gpt-4o-mini", "messages": [{"role": "user", "content": prompt}], "temperature": 0.7}
    
    try:
        async with httpx.AsyncClient(timeout=20) as client:
            resp = await client.post("https://api.openai.com/v1/chat/completions", json=body, headers=headers)
            resp.raise_for_status()
            data = resp.json()
            content = data["choices"][0]["message"]["content"]
            
            # Extract questions from content
            lines = content.split('\n')
            questions = []
            for line in lines:
                line = line.strip()
                if line and ('diyelim ki' in line.lower() or 'diyelim' in line.lower()):
                    # Remove bullet points, numbers, etc.
                    clean_line = line.lstrip('- â€¢*123456789.').strip()
                    if clean_line:
                        questions.append(clean_line)
            
            return questions[:8]  # Max 8 questions
    except Exception:
        return []