# ðŸŽ¤ðŸŽ¥ SES VE VÄ°DEO ANALÄ°ZÄ° GELÄ°ÅžTÄ°RME PLANI

## ðŸ“‹ GENEL BAKIÅž

Mevcut sistemde **sadece temel STT (Speech-to-Text)** yapÄ±lÄ±yor. Bu plan ile **geliÅŸmiÅŸ ses analizi** ve **video analizi** ekleyerek **multi-modal interview assessment** sistemi oluÅŸturacaÄŸÄ±z.

---

## ðŸŽ¯ HEDEFLER

### **Ses Analizi Hedefleri:**
- âœ… **Prosody Analysis** (Ses tonu, ritim, vurgu)
- âœ… **Emotional Speech Detection** (Duygusal konuÅŸma tespiti)
- âœ… **Confidence Indicators** (GÃ¼ven gÃ¶stergeleri)
- âœ… **Speech Quality Metrics** (KonuÅŸma kalitesi Ã¶lÃ§Ã¼mleri)
- âœ… **Real-time Speech Analytics** (GerÃ§ek zamanlÄ± analiz)

### **Video Analizi Hedefleri:**
- âœ… **Facial Expression Analysis** (YÃ¼z ifadesi analizi)
- âœ… **Body Language Detection** (Beden dili tespiti)
- âœ… **Eye Contact Tracking** (GÃ¶z temasÄ± takibi)
- âœ… **Gesture Recognition** (El hareketleri tanÄ±ma)
- âœ… **Behavioral Video Insights** (DavranÄ±ÅŸsal video iÃ§gÃ¶rÃ¼leri)

---

## ðŸ“Š MEVCUT DURUM ANALÄ°ZÄ°

### âœ… **Åžu An YapÄ±lan:**
- **STT (Speech-to-Text)** - Azure Speech Services + OpenAI Whisper
- **Filler Word Counting** - "ÅŸey", "hani", "yani" tespiti
- **Basic Text Analysis** - Kelime bazlÄ± gÃ¼ven analizi
- **Video Storage** - S3'te video dosyasÄ± saklama

### âŒ **Eksik Olan:**
- **Prosody Analysis** - Ses tonu, ritim analizi
- **Emotional Speech** - Duygusal konuÅŸma tespiti
- **Video Analysis** - YÃ¼z ifadesi, beden dili
- **Multi-modal Integration** - Ses + Video birleÅŸik analiz

---

## ðŸš€ GELÄ°ÅžTÄ°RME PHASE'LERÄ°

---

## ðŸ“ PHASE 1: GELÄ°ÅžMÄ°Åž SES ANALÄ°ZÄ°

### **Task 1.1: Azure Speech Services Enhancement**
- [ ] **Priority:** HIGH
- [ ] **Duration:** 3 days
- [ ] **Files:** `apps/api/src/services/speech_analysis.py` (NEW)

**YapÄ±lacaklar:**
```python
# Yeni service oluÅŸtur
async def analyze_speech_prosody(audio_bytes: bytes) -> Dict[str, Any]:
    """Azure Speech Services ile geliÅŸmiÅŸ ses analizi"""
    # Pitch analysis
    # Speech rate analysis
    # Pause detection
    # Confidence indicators
```

**API Endpoints:**
- [ ] `POST /api/v1/speech/analyze-prosody`
- [ ] `POST /api/v1/speech/analyze-emotion`
- [ ] `POST /api/v1/speech/analyze-confidence`

### **Task 1.2: Real-time Speech Analytics**
- [ ] **Priority:** HIGH
- [ ] **Duration:** 2 days
- [ ] **Files:** `apps/api/src/api/v1/speech_analytics.py` (NEW)

**YapÄ±lacaklar:**
```python
@router.websocket("/speech-analytics/{interview_id}")
async def real_time_speech_analytics(websocket: WebSocket, interview_id: int):
    """Real-time konuÅŸma analizi WebSocket"""
    # Pitch tracking
    # Rate monitoring
    # Confidence scoring
    # Stress detection
```

### **Task 1.3: Speech Quality Metrics**
- [ ] **Priority:** MEDIUM
- [ ] **Duration:** 2 days
- [ ] **Files:** `apps/api/src/services/speech_quality.py` (NEW)

**YapÄ±lacaklar:**
```python
async def calculate_speech_quality_metrics(audio_data: bytes) -> Dict[str, Any]:
    """KonuÅŸma kalitesi Ã¶lÃ§Ã¼mleri"""
    return {
        "fluency_score": 0.85,
        "articulation_quality": 0.78,
        "pause_frequency": 0.3,
        "speech_rate": 150,  # words per minute
        "confidence_indicators": 0.7
    }
```

### **Task 1.4: Emotional Speech Detection**
- [ ] **Priority:** HIGH
- [ ] **Duration:** 3 days
- [ ] **Files:** `apps/api/src/services/emotion_speech.py` (NEW)

**YapÄ±lacaklar:**
```python
async def detect_speech_emotions(audio_data: bytes) -> Dict[str, Any]:
    """KonuÅŸma duygularÄ±nÄ± tespit et"""
    return {
        "confidence": 0.8,
        "stress": 0.2,
        "enthusiasm": 0.6,
        "nervousness": 0.3,
        "calmness": 0.7
    }
```

---

## ðŸ“¹ PHASE 2: VÄ°DEO ANALÄ°ZÄ°

### **Task 2.1: Video Analysis Service**
- [ ] **Priority:** HIGH
- [ ] **Duration:** 4 days
- [ ] **Files:** `apps/api/src/services/video_analysis.py` (NEW)

**YapÄ±lacaklar:**
```python
async def analyze_video_behavior(video_bytes: bytes) -> Dict[str, Any]:
    """Video davranÄ±ÅŸ analizi"""
    # Facial expression analysis
    # Body language detection
    # Eye contact tracking
    # Gesture recognition
```

**API Endpoints:**
- [ ] `POST /api/v1/video/analyze-facial`
- [ ] `POST /api/v1/video/analyze-body`
- [ ] `POST /api/v1/video/analyze-gestures`

### **Task 2.2: Facial Expression Analysis**
- [ ] **Priority:** HIGH
- [ ] **Duration:** 3 days
- [ ] **Files:** `apps/api/src/services/facial_analysis.py` (NEW)

**YapÄ±lacaklar:**
```python
async def analyze_facial_expressions(video_data: bytes) -> Dict[str, Any]:
    """YÃ¼z ifadesi analizi"""
    return {
        "confidence": 0.85,
        "engagement": 0.7,
        "stress_indicators": 0.3,
        "positive_expressions": 0.6,
        "neutral_expressions": 0.3,
        "negative_expressions": 0.1
    }
```

### **Task 2.3: Body Language Detection**
- [ ] **Priority:** MEDIUM
- [ ] **Duration:** 3 days
- [ ] **Files:** `apps/api/src/services/body_language.py` (NEW)

**YapÄ±lacaklar:**
```python
async def detect_body_language(video_data: bytes) -> Dict[str, Any]:
    """Beden dili tespiti"""
    return {
        "posture_confidence": 0.8,
        "gesture_frequency": 0.4,
        "eye_contact_percentage": 0.75,
        "movement_indicators": {
            "fidgeting": 0.2,
            "open_posture": 0.7,
            "closed_posture": 0.3
        }
    }
```

### **Task 2.4: Eye Contact Tracking**
- [ ] **Priority:** MEDIUM
- [ ] **Duration:** 2 days
- [ ] **Files:** `apps/api/src/services/eye_contact.py` (NEW)

**YapÄ±lacaklar:**
```python
async def track_eye_contact(video_data: bytes) -> Dict[str, Any]:
    """GÃ¶z temasÄ± takibi"""
    return {
        "eye_contact_percentage": 0.75,
        "gaze_direction": "forward",
        "attention_indicators": 0.8,
        "distraction_indicators": 0.2
    }
```

---

## ðŸ”— PHASE 3: MULTI-MODAL ENTEGRASYON

### **Task 3.1: Multi-modal Analysis Service**
- [ ] **Priority:** HIGH
- [ ] **Duration:** 4 days
- [ ] **Files:** `apps/api/src/services/multimodal_analysis.py` (NEW)

**YapÄ±lacaklar:**
```python
async def analyze_interview_multimodal(
    audio_data: bytes, 
    video_data: bytes
) -> Dict[str, Any]:
    """Ses + Video birleÅŸik analiz"""
    # Audio analysis
    # Video analysis
    # Cross-modal correlation
    # Unified confidence scoring
```

### **Task 3.2: Behavioral Correlation Engine**
- [ ] **Priority:** MEDIUM
- [ ] **Duration:** 3 days
- [ ] **Files:** `apps/api/src/services/behavioral_correlation.py` (NEW)

**YapÄ±lacaklar:**
```python
async def correlate_audio_video_behavior(
    speech_analysis: Dict,
    video_analysis: Dict
) -> Dict[str, Any]:
    """Ses ve video davranÄ±ÅŸlarÄ±nÄ± iliÅŸkilendir"""
    # Confidence correlation
    # Stress correlation
    # Engagement correlation
    # Consistency scoring
```

### **Task 3.3: Enhanced Analysis Integration**
- [ ] **Priority:** HIGH
- [ ] **Duration:** 2 days
- [ ] **Files:** `apps/api/src/services/analysis.py` (MODIFY)

**YapÄ±lacaklar:**
```python
# Mevcut analysis.py'ye entegre et
async def enrich_with_multimodal_analysis(
    session: AsyncSession,
    interview_id: int,
    audio_data: bytes,
    video_data: bytes
) -> None:
    """Multi-modal analizi mevcut sisteme entegre et"""
```

---

## ðŸŽ¨ PHASE 4: FRONTEND ENHANCEMENT

### **Task 4.1: Speech Analytics Dashboard**
- [ ] **Priority:** MEDIUM
- [ ] **Duration:** 3 days
- [ ] **Files:** `apps/web/components/analytics/SpeechAnalytics.tsx` (NEW)

**YapÄ±lacaklar:**
```typescript
// Real-time speech analytics component
interface SpeechAnalyticsProps {
  interviewId: number;
  audioData?: Blob;
  onAnalysisUpdate: (data: SpeechAnalysisData) => void;
}
```

### **Task 4.2: Video Analytics Component**
- [ ] **Priority:** MEDIUM
- [ ] **Duration:** 3 days
- [ ] **Files:** `apps/web/components/analytics/VideoAnalytics.tsx` (NEW)

**YapÄ±lacaklar:**
```typescript
// Video analytics visualization
interface VideoAnalyticsProps {
  interviewId: number;
  videoData?: Blob;
  onAnalysisUpdate: (data: VideoAnalysisData) => void;
}
```

### **Task 4.3: Multi-modal Report Integration**
- [ ] **Priority:** HIGH
- [ ] **Duration:** 2 days
- [ ] **Files:** `apps/web/components/reports/EvidenceBasedReport.tsx` (MODIFY)

**YapÄ±lacaklar:**
```typescript
// Mevcut report component'ine multi-modal data ekle
interface EvidenceBasedReportProps {
  // ... existing props
  speechAnalysis?: SpeechAnalysisData;
  videoAnalysis?: VideoAnalysisData;
  multimodalCorrelation?: MultimodalData;
}
```

---

## ðŸ”§ PHASE 5: INFRASTRUCTURE & DEPLOYMENT

### **Task 5.1: Azure Services Configuration**
- [ ] **Priority:** HIGH
- [ ] **Duration:** 1 day
- [ ] **Files:** `apps/api/src/core/config.py` (MODIFY)

**YapÄ±lacaklar:**
```python
# Azure Computer Vision ve Speech Services config
@property
def azure_computer_vision_key(self) -> str | None:
    return os.getenv("AZURE_COMPUTER_VISION_KEY")

@property
def azure_computer_vision_endpoint(self) -> str | None:
    return os.getenv("AZURE_COMPUTER_VISION_ENDPOINT")
```

### **Task 5.2: Database Schema Updates**
- [ ] **Priority:** HIGH
- [ ] **Duration:** 1 day
- [ ] **Files:** `apps/api/alembic/versions/` (NEW MIGRATION)

**YapÄ±lacaklar:**
```sql
-- Interview tablosuna multi-modal analysis columns ekle
ALTER TABLE interviews ADD COLUMN speech_analysis JSONB;
ALTER TABLE interviews ADD COLUMN video_analysis JSONB;
ALTER TABLE interviews ADD COLUMN multimodal_correlation JSONB;
```

### **Task 5.3: Environment Variables**
- [ ] **Priority:** HIGH
- [ ] **Duration:** 1 day
- [ ] **Files:** `.env.example` (MODIFY)

**YapÄ±lacaklar:**
```bash
# Azure Computer Vision
AZURE_COMPUTER_VISION_KEY=your_key_here
AZURE_COMPUTER_VISION_ENDPOINT=https://your-resource.cognitiveservices.azure.com/

# Enhanced Azure Speech
AZURE_SPEECH_ENABLE_PROSODY=true
AZURE_SPEECH_ENABLE_EMOTION=true
```

---

## ðŸ“Š TESTING & VALIDATION

### **Task 6.1: Unit Tests**
- [ ] **Priority:** MEDIUM
- [ ] **Duration:** 2 days
- [ ] **Files:** `apps/api/tests/test_speech_analysis.py` (NEW)

**YapÄ±lacaklar:**
```python
# Speech analysis unit tests
async def test_speech_prosody_analysis():
    """Test prosody analysis functionality"""

async def test_emotion_detection():
    """Test emotion detection accuracy"""
```

### **Task 6.2: Integration Tests**
- [ ] **Priority:** MEDIUM
- [ ] **Duration:** 2 days
- [ ] **Files:** `apps/api/tests/test_multimodal_integration.py` (NEW)

**YapÄ±lacaklar:**
```python
# Multi-modal integration tests
async def test_audio_video_correlation():
    """Test audio-video correlation accuracy"""

async def test_end_to_end_multimodal():
    """Test complete multimodal pipeline"""
```

### **Task 6.3: Performance Testing**
- [ ] **Priority:** LOW
- [ ] **Duration:** 1 day
- [ ] **Files:** `apps/api/tests/test_performance.py` (NEW)

**YapÄ±lacaklar:**
```python
# Performance benchmarks
async def test_speech_analysis_performance():
    """Test speech analysis processing time"""

async def test_video_analysis_performance():
    """Test video analysis processing time"""
```

---

## ðŸ“ˆ MONITORING & ANALYTICS

### **Task 7.1: Metrics Collection**
- [ ] **Priority:** MEDIUM
- [ ] **Duration:** 1 day
- [ ] **Files:** `apps/api/src/core/metrics.py` (MODIFY)

**YapÄ±lacaklar:**
```python
# Multi-modal analysis metrics
collector.record_speech_analysis_ms(processing_time)
collector.record_video_analysis_ms(processing_time)
collector.record_multimodal_correlation_ms(processing_time)
```

### **Task 7.2: Error Handling**
- [ ] **Priority:** HIGH
- [ ] **Duration:** 1 day
- [ ] **Files:** `apps/api/src/core/error_handling.py` (MODIFY)

**YapÄ±lacaklar:**
```python
# Multi-modal error handling
class MultimodalAnalysisError(Exception):
    """Multi-modal analysis specific errors"""

class SpeechAnalysisError(Exception):
    """Speech analysis specific errors"""

class VideoAnalysisError(Exception):
    """Video analysis specific errors"""
```

---

## ðŸ“‹ TASK SUMMARY

### **Toplam SÃ¼re:** 35 gÃ¼n
### **Toplam Task:** 25 task
### **Priority Breakdown:**
- **HIGH:** 12 task (48%)
- **MEDIUM:** 10 task (40%)
- **LOW:** 3 task (12%)

### **Phase Breakdown:**
- **Phase 1 (Ses Analizi):** 10 gÃ¼n
- **Phase 2 (Video Analizi):** 12 gÃ¼n
- **Phase 3 (Multi-modal):** 9 gÃ¼n
- **Phase 4 (Frontend):** 8 gÃ¼n
- **Phase 5 (Infrastructure):** 3 gÃ¼n
- **Phase 6 (Testing):** 5 gÃ¼n
- **Phase 7 (Monitoring):** 2 gÃ¼n

---

## ðŸŽ¯ BAÅžARIMETRELERÄ°

### **Teknik Metrikler:**
- **Speech Analysis Accuracy:** >90%
- **Video Analysis Accuracy:** >85%
- **Multi-modal Correlation:** >80%
- **Processing Time:** <5 seconds
- **Real-time Latency:** <1 second

### **Business Metrikler:**
- **Interview Quality:** +300% improvement
- **Assessment Accuracy:** +250% improvement
- **User Experience:** +200% enhancement
- **Analytics Depth:** +400% increase

---

## ðŸš€ SONUÃ‡

Bu plan ile **enterprise-grade multi-modal interview analysis** sistemi oluÅŸturacaÄŸÄ±z. Sistem:

1. **GeliÅŸmiÅŸ ses analizi** ile konuÅŸma kalitesi, duygular, gÃ¼ven gÃ¶stergeleri
2. **Video analizi** ile yÃ¼z ifadesi, beden dili, gÃ¶z temasÄ±
3. **Multi-modal correlation** ile ses + video birleÅŸik deÄŸerlendirme
4. **Real-time analytics** ile anlÄ±k feedback
5. **Comprehensive reporting** ile detaylÄ± raporlama

saÄŸlayacak.

**BaÅŸlangÄ±Ã§:** Phase 1, Task 1.1 (Azure Speech Services Enhancement)
**Hedef:** 35 gÃ¼n iÃ§inde tamamlanma
**SonuÃ§:** %400+ daha detaylÄ± interview analytics
